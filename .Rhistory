expand.grid(0:1, 1:2)
expand.grid(0:1, 1:3)
expand.grid(matmaker_list)
dim(matmaker_list)
dims(matmaker_list)
matmaker_list
matmaker_list
expand.grid(matmaker_list)
matmaker_list
combos_matrix <- expand.grid(matmaker_list)
expand.grid(matmaker_list)
class(combos_matrix)
t(combos_matrix)
is_vector %*% t(combos_matrix)
answer <- is_vector %*% t(combos_matrix)
unique(sort(answer))
install.package('ggplot2')
install.packages('ggplot2')
library('ggplot2')
head(diamonds)
str(diamonds) # str for structure
names(diamonds)
p + geom_histogram()
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(x = clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(clarity))
p + geom_histogram()
library('ggplot2')
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes=(x=clarity, y=1))
p + geom_histogram()
help(ggplot)
install.packages('ggplot2')
install.packages("ggplot2")
install.packages("ggplot2")
library('ggplot2')
p <- ggplot(diamonds, aes=(x=clarity))
p + geom_histogram()
help(ggplot)
p <- ggplot(diamonds, aes=(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes = ( y = clarity ))
p + geom_histogram()
getwd()
head(diamonds)
str(diamonds) # str for structure
names(diamonds)
# plot preparation
p <- ggplot(diamonds, aes=(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(y=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut))
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut), main='hi')
p + geom_histogram()
p <- ggplot(diamonds, aes(x=clarity, fill=cut))
p + geom_histogram() + opts(title='Chart')
p + geom_histogram() + labs(title='Chart')
head(mtcars)
length(mtcars)
mtcars
head(mtcars)
names(mtcars)
p <- qplot(wt, mpg, data=mtcars)
p + geom_abline()
coeff(lm(mpg ~ wt), data=mtcars)
coef(lm(mpg ~ wt), data=mtcars)
coef(lm(mpg ~ wt, data=mtcars))
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept=20)
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept = 10, colour = "red", size = 2)
p + geom_abline(intercept = 10, color = "red", size = 2)
p + geom_abline(intercept=37.285, slope=-5.344)
p + geom_abline(intercept = 10, color = "red", size = 2)
map_data("nz")
install.packages('psych')
search()
?data.frame
numbers <- 1:10
words <- c('one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten')
nw <- cbind(numbers, words)
nw
attributes(nw)
nw
nw$numbers
nw[8, 1]
nw[8, 2]
matrix(1:10, c(2, 5))
x <- 1:6
y <- 5:10
class(rbind(x, y))
rnorm(1, 6043834, 6823984)
rnorm(51, 6043834, 6823984)
hist(rnorm(51, 6043834, 6823984))
library(ggplot2)
library(maps)
install.packages('maps')
all_states <- map_data('state')
p <- ggplot()
p <- p + geom_polygon(data=all_states, aes(x=long, y=lat, group=group), color='white', fill='grey10')
p
world <- map_data('nation')
world <- map_data('country')
world <- map_data('world')
all_states
head(all_states)
unique(group)
unique(all_states$group)
nrow(all_states)
states <- subset(all_states,
region %in% c( "illinois",
"indiana",
"iowa",
"kentucky",
"michigan",
"minnesota",
"missouri",
"north dakota",
"ohio",
"south dakota",
"wisconsin" ))
p <- ggplot()
p <- p + geom_polygon(data=states,
aes(x=long, y=lat, group=group),
color='white',
fill='grey10')
p
getwd()
set.seed(31)
heightCM = rnorm(30, mean=188, sd=5)
weightsK = rnorm(30, mean=84, sd=3)
hasDaughter = sample(c(TRUE, FALSE), size=30, replace=T)
dataFrame = data.frame(heightsCM, weightsK, hasDaughter)
dataFrame = data.frame(heightCM, weightsK, hasDaughter)
names(dataFrame)
subset <- dataFrame[, dataFrame$heightCM >= 188]
condition <- dataFrame$heightCM >= 188
condition
subset <- dataFrame[condition, ]
getwd()
mean(subset$weightsK)
set.seed(41)
install.packages('tseries')
library(tseries)
library(tseries)
data(bev)
bev
data(nino)
nino
data(tcm)
tcm
?rm.packages()
?remove.packages()
?remove.packages(tseries)
remove.packages(tseries)
remove.packages('tseries')
library(ISLR)
set.seed(1)
train = sample(392, 196)
head(train)
length(train)
lm.fit <- lm(mpg ~ horsepower, data=Auto, subset=train)
attach(Auto)
length(predict(lm.fit))
length(mpg)
mean((mpg - predict(lm.fit, Auto))[-train]^2)
(mpg - predict(lm.fit, Auto))[-train]^2
mean((mpg - predict(lm.fit, Auto))[-train]^2)
lm.fit2 <- lm(mpg ~ poly(horsepower, 2), data=Auto, subset=train)
mean((mpg - predict(lm.fit2, Auto))[-train]^2)
lm.fit3 <- lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)
mean((mpg - predict(lm.fit3, Auto))[-train]^2)
library(boot)
glm.fit = glm(mpg ~ horsepower, data=Auto)
cv.error = cv.glm(Auto, glm.fit)
cv.error$delta
cv.error = rep(0, 5)
for (i in 1:5) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
set.seed(17)
cv.error.10 = rep(0, 10)
for (i in 10) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
for (i in 1:10) {
glm.fit = glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
head(Portfolio)
?Portfolio
summary(Portfolio)
alpha.fn = function(data, index) {
X = data$X[index]
Y = data$Y[index]
return((var(Y) - cov(X, Y)) / (var(X) + var(Y) - 2 * cov(X, Y)))
}
alpha.fn(Portfolio, 1:1000)
alpha.fn(Portfolio, 1:100)
X = data$X[1:100]
boot(Portfolio, alpha.fn, R=1000)
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower, data=data, subset=index)))
}
head(Auto)
names(Auto)
dim(Auto)
boot.fn(Auto, 1:392)
set.seed(1)
boot.fn(Auto, sample(392, 392, replace=T))
boot.fn(Auto, sample(392, 392, replace=T))
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower, data=Auto))$coef
?I
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower + I(horsepower^2), data=data, subset=Index)))
}
set.seed(1)
boot(Auto, boot.fn, 1000)
boot.fn = function(data, index) {
return(coef(lm(mpg ~ horsepower + I(horsepower^2), data=data, subset=index)))
}
set.seed(1)
boot(Auto, boot.fn, 1000)
summary(lm(mpg ~ horsepower + I(horsepower^2), data=data))$coef
summary(lm(mpg ~ horsepower + I(horsepower^2), data=Auto))$coef
install.packages("shiny")
library(shiny)
a <- matrix(1:10, 5, 2)
a
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, ))
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, 0.54, 0.45, 0.374, 0.447, 0.5))
a <- matrix(c(0.338, 0.391, 0.369, 0.313, 0.361, 0.54, 0.45, 0.374, 0.447, 0.5), 5, 2)
a
b <- matrix(c(2737.77, 1584.91))
b
a * b
a %*% b
c <- a %*% b
c - 804.63
c <- c - 804.63
c
d <- matrix(c(1400000, 1065000, 295000, 800000, 300000))
d % c
d / c
teamRank = c(1,2,3,3,4,4,4,4,5,5)
r2012 <- c(94, 88, 95, 88, 93, 94, 98, 97, 93, 94)
r2013 <- c(97, 97, 92, 93, 92, 96, 94, 96, 92, 90)
cor(teamRank, r2012)
cor(teamRank, r2013)
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
myPlot(3)
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
dTable(airquality, sPaginationType = "full_numbers")
airquality
library(rCharts)
dTable(airquality, sPaginationType = "full_numbers")
ls
a <- 1:30
b <- 5:35
a - b
b - a
head(a)
head(b)
class(a)
setdiff(a, b)
data(mtcars)
head(airquality)
head(airquality)
nrow(airquality)
xcomplete.cases(airquality)
x <- airquality[complete.cases(airquality), ]
nrow(x)
data(airquality)
cor(airquality)
head(airquality)
min(Ozone)
min(airquality$Ozone)
plot(Solar.R ~ Wind, airquality)
head(airquality)
library(ggplot2)
ggplot(airquality) +
geom_point(aes(x = Wind, y = Ozone, fill = Month))
ggplot(airquality) +
geom_point(aes(x = Wind, y = Ozone, color = Month))
ggplot(airquality) +
geom_point(aes(x = Wind, y = Ozone)) +
facet_grid(Month ~ .)
head(airquality)
cor(airquality, na.rm = T)
cor(airquality, rm.na = T)
cor(airquality)
x <- airquality[complete.cases(airquality), ]
x <- cor(airquality)
cor(x)
head(x)
x <- airquality[complete.cases(airquality), ]
head(x)
cor(x)
ggplot(x) +
geom_point(aes(x = Temp, y = Ozone))
ggplot(x) +
geom_point(aes(x = Temp, y = Ozone)) +
facet_grid(Month ~ .)
a <- 1:30
b <- 5:35
setdiff(a, b)
a
b
a - b
setdiff(b, a)
a[a %in% b]
a[!(a %in% b)]
subset(airquality, na = TRUE)
subset(airquality, nm = TRUE)
subset(airquality, complete.cases(airquality))
subset(airquality, !complete.cases(airquality))
g = D(x^2 ~ x)
install.packages('mosaic')
library(mosaic)
g = D(x^2 ~ x)
g
g(2)
D(sin(x) ~ x)
D(cos(x) ~ x)
h <- D(sin(abs(x - 3)) ~ x)
h
h(2)
sin(90)
?since
?sin
waterLM <- lm(y ~ A * B * C)
A <- c(-1, -1, -1, +1)
B <- c(-1, +1, -1, +1)
C <- c(-1, -1, +1, +1)
y <- c(30, 6, 4, 8)
waterLM <- lm(y ~ A * B * C)
summary(waterLM)
x <- c(1, 2, 3, 4)
sd(x)
update.packages()
rm(list = ls())
?aggregate
rm(list = ls())
library(DBI)
rm(list = ls())
getwd()
library(leafletR)
library(rgdal) #for reading/writing geo files
install.packages('rgdal')
install.packages(geos, type="source")
install.packages('geos', type="source")
install.packages('rgdal', type="source")
library(rgdal) #for reading/writing geo files
install.packages('geos', type="source")
install.packages('geos')
library(leaftlet)
library(leaftletR)
library(leafletR)
library(leaftlet)
install.packages('leaflet')
detach('package:leafletR')
if(!require(devtools)) install.packages("devtools")
if(!require(leaflet)) install_github("rstudio/leaflet")
library(leaflet)
if(!require(leaflet)) install_github("rstudio/leaflet")
(m <- leaflet() %>% addTiles())
(m <- leaflet() %>% addTiles())
install_github("rstudio/leaflet")
library(leaflet)
(m <- leaflet() %>% addTiles())
m <- leaflet() %>% addTiles()
m
(m)
img <- readPNG("~/repos/Creating-maps-in-R/figure//shiny_world.png")
m
library(RCurl) # download https data
urlfile <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'
x <- getURL(urlfile, ssl.verifypeer = FALSE)
adults <- read.csv(textConnection(x), header=F)
# if the above getURL command fails, try this:
# adults <-read.csv('https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data', header=F)
names(adults)=c('Age','Workclass','FinalWeight','Education','EducationNumber',
'MaritalStatus','Occupation','Relationship','Race',
'Sex','CapitalGain','CapitalLoss','HoursWeek',
'NativeCountry','Income')
adults$Income <- ifelse(adults$Income==' <=50K',0,1)
library(caret)
dmy <- dummyVars(" ~ .", data = adults)
adultsTrsf <- data.frame(predict(dmy, newdata = adults))
## Correlation matrix with p-values. See http://goo.gl/nahmV for documentation of this function
cor.prob <- function (X, dfr = nrow(X) - 2) {
R <- cor(X, use="pairwise.complete.obs")
above <- row(R) < col(R)
r2 <- R[above]^2
Fstat <- r2 * dfr/(1 - r2)
R[above] <- 1 - pf(Fstat, 1, dfr)
R[row(R) == col(R)] <- NA
R
}
## Use this to dump the cor.prob output to a 4 column matrix
## with row/column indices, correlation, and p-value.
## See StackOverflow question: http://goo.gl/fCUcQ
flattenSquareMatrix <- function(m) {
if( (class(m) != "matrix") | (nrow(m) != ncol(m))) stop("Must be a square matrix.")
if(!identical(rownames(m), colnames(m))) stop("Row and column names must be equal.")
ut <- upper.tri(m)
data.frame(i = rownames(m)[row(m)[ut]],
j = rownames(m)[col(m)[ut]],
cor=t(m)[ut],
p=m[ut])
}
x <- cor.prob(adultsTrsf)
head(x)
library(caret)
remove(list=ls9)
remove(list=ls())
library(caret)
remove(list=ls())
names(getModelInfo())
names(getModelInfo())
library(RCurl)
urlfile <-'https://raw.githubusercontent.com/hadley/fueleconomy/master/data-raw/vehicles.csv'
?getURL
x <- getURL(urlfile, ssl.verifypeer = FALSE)
class(x)
head(x)
vehicles <- read.csv(textConnection(x))
head(vehicles)
dim(vehicles)
?repeat
?repeat
remove(list=ls())
titanicDF <- read.csv('http://math.ucdenver.edu/RTutorial/titanic.txt',sep='\t')
head(titanicDF)
titanicDF$Title <- ifelse(grepl('Mr ',titanicDF$Name),'Mr',ifelse(grepl('Mrs ',titanicDF$Name),'Mrs',ifelse(grepl('Miss',titanicDF$Name),'Miss','Nothing')))
titanicDF$Title <- as.factor(titanicDF$Title)
titanicDF$Age[is.na(titanicDF$Age)] <- median(titanicDF$Age, na.rm=T)
titanicDF <- titanicDF[c('PClass', 'Age',    'Sex',   'Title', 'Survived')]
require(caret)
titanicDummy <- dummyVars("~.",data=titanicDF, fullRank=F)
titanicDF <- as.data.frame(predict(titanicDummy,titanicDF))
head(titanicDF)
summary(titanicDF)
df_survived_1 <- subset(titanicDF, Survived==1)
df_survived_0 <- subset(titanicDF, Survived==0)
summary(df_survived_1$Sex.female)
summary(df_survived_0$Sex.female)
class(summary(df_survived_0$Sex.female))
Sex.Female_0 <- (summary(df_survived_0$Sex.female))
Sex.Female_0
class(Sex.Female_0)
Sex.Female_0 <- summary(df_survived_0$Sex.female)
class(Sex.Female_0)
Sex.Female_0
Sex.Female_0 <- c(Sex.Female_0[1:6])
Sex.Female_0
class(Sex.Female_0)
Sex.Female_0 <- as.numeric(summary(df_survived_0$Sex.female))
Sex.Female_0
Sex.Female_0 <- summary(df_survived_0$Sex.female)
Sex.Female_0 <- c(Sex.Female_0[1:6])
Sex.Female_1 <- (summary(df_survived_1$Sex.female))
Sex.Female_1 <- c(Sex.Female_1[1:6])
stats <- data.frame('ind'=c(1:6),
'Sex.Female_1'=Sex.Female_1,
'Sex.Female_0'=Sex.Female_0)
stats
Sex.Female_1
str(Sex.Female_1)
class(Sex.Female_1)
names(Sex.Female_1)
Sex.Female_1 <- summary(df_survived_1$Sex.female)
Sex.Female_1 <- c(Sex.Female_1)
Sex.Female_1
class(Sex.Female_1)
Sex.Female_0 <- c(Sex.Female_0)
stats <- data.frame('ind'=c(1:6),
'Sex.Female_1'=Sex.Female_1,
'Sex.Female_0'=Sex.Female_0)
stats
require(ggplot2)
p <- ggplot(data=stats, aes(ind)) +
geom_line(aes(y = Sex.Female_1, colour = "Sex.Female_1")) +
geom_line(aes(y = Sex.Female_0, colour = "Sex.Female_0")) +
scale_x_discrete(breaks = 1:6,
labels=c("min","1q","median","mean","3q","max"))
p
rm(list = ls())
getwd()
setwd('/Users/hawooksong/Desktop/shiny_data_explorer')
library(shiny)
runApp()
runApp()
runApp()
