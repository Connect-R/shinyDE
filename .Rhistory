logs <- loadLogs(rawDatasetFileName, dataPrevProc, missTypes)
rawDatasetFileName <- '53009054_main-Supermercati_Poli.csv'  # distinct double vs. single humps
logs <- loadLogs(rawDatasetFileName, dataPrevProc, missTypes)
daily <- loadDaily(rawDatasetFileName, dataPrevAgg, missTypes)
monthly <- loadMonthly(rawDatasetFileName, dataPrevAgg, missTypes)
# for week clustering uncomment below line and comment above line
logs <- processRawLogs(logs, dataPrevProc , clustType = 'Day')
dataPrevAggWeekly <- F
daily <- aggregateDaily(logs, daily, dataPrevAgg)
weekly <- aggregateWeekly(daily,weekly, dataPrevAggWeekly)
monthly <- aggregateMonthly(logs, monthly, dataPrevAgg)
## this function aggregates raw data using functions from dplyr
aggregate <- function(df, aggBy, aggTarget, aggMeth, nRndDeci=2) {
## select independent/dependent variables
df <- df[, c(aggBy, aggTarget)]
## conditional to perform count later
cntInAggMeth <- 'count' %in% aggMeth
nonCntAggMeth <- setdiff(aggMeth, 'count')
## convert character vector to list of symbols
dots <- lapply(aggBy, as.symbol)
## group data
grp <- group_by_(df, .dots=dots)
## perform non-count aggregation by column
agg <- summarise_each(grp, funs_(nonCntAggMeth))
## attach aggregate counts if requested
if (cntInAggMeth) {
cnt <- dplyr::summarise(grp, count=n())
agg$count <- cnt$count
}
## convert to data frame
agg <- as.data.frame(agg)
## rename column names
agg <- renameAggColNames(agg, aggBy, aggTarget, aggMeth)
## find numeric columns and round
numericVars <- getNumericVarNames(agg)
#agg[numericVars] <- sapply(agg[numericVars], function(x) {round(x, nRndDeci)})
for (numericVar in numericVars) {
agg[[numericVar]] <- round(agg[[numericVar]], nRndDeci)
}
## return
agg
}
## this function renames column names of aggregate df
renameAggColNames <- function(df, aggBy, aggTarget, aggMeth) {
cntInAggMeth <- 'count' %in% aggMeth
aggMeth <- setdiff(aggMeth, 'count')
colnames <- c(aggBy)
for (meth in aggMeth) {
for (targ in aggTarget) {
colname <- paste(targ, meth, sep='_')
colnames <- c(colnames, colname)
}
}
if (cntInAggMeth) {
colnames <- c(colnames, 'count')
}
colnames(df) <- colnames
return(df)
}
## this function grabs the names of numeric variables
getNumericVarNames <- function(df) {
numericVars <- colnames(df)[sapply(df, is.numeric)]
return(numericVars)
}
## This function takes in logs dataset for a single sensor and adds new columns for
## various aggregation method, such as:
## 1. number of data points (count)
## 2. average usage values (mean)
## 3. total usage values (sum)
## for each category from cat1 through cat7.
calcCatValsSingleSensor <- function(logsDF, tFrame, aggMeth) {
aggTarget <- 'usage'
if (tFrame=='daily') {
aggBy <- c('date', 'cat')
catVals_long <- aggregate(logsDF, aggBy, aggTarget, aggMeth)
catVals_wide <- data.table::dcast(setDT(catVals_long), date ~ cat, value.var=c('usage_mean', 'usage_sum', 'count'))
} else if (tFrame=='monthly') {
aggBy <- c('year', 'month', 'cat')
catVals_long <- aggregate(logsDF, aggBy, aggTarget, aggMeth)
catVals_wide <- data.table::dcast(setDT(catVals_long), year + month ~ cat, value.var=c('usage_mean', 'usage_sum', 'count'))
}
## impute NAs with 0s
numericVars <- getNumericVarNames(catVals_wide)
for (var in numericVars) {
catVals_wide[[var]][is.na(catVals_wide[[var]])] <- 0
}
## return
return(catVals_wide)
}
## this function takes logs dataset for a single sensor
## and calculates various daily aggregation metrics by date
calcDailyAggSingleSensor <- function(logsDF, nRndDeci=3) {
## print meter ID
print(paste('Calculating daily aggregation for', logsDF$meterID[1]))
## define aggregation methods
aggMeth <- c('count', 'sum', 'mean', 'sd', 'max', 'min')
## calculate basic daily aggregation metrics per day
print(paste('Calculating daily', paste(aggMeth, collapse=', '), '...'))
dailyAggDF <- aggregate(df=logsDF, aggBy='date', aggTarget='usage', aggMeth=aggMeth)
## add year, month, and yearMonth columns to daily aggregation df
dailyAggDF <- addYearMonth(dailyAggDF, dateVar='date')
## calculate daily category values per day
print(paste('Calculating daily category values of', paste(aggMeth, collapse=', '), '...'))
dailyCatValsDF <- calcCatValsSingleSensor(logsDF, 'daily', aggMeth)
dailyAggDF <- merge(dailyAggDF, dailyCatValsDF, by='date')
## calculate time interval used per day
print('Calculating daily time interval used for measurement ...')
dailyTimeIntDF <- aggregate(logsDF, aggBy='date', aggTarget='tInt', aggMeth='unique')
colnames(dailyTimeIntDF)[colnames(dailyTimeIntDF)=='tInt_unique'] <- 'tInt'
dailyAggDF <- merge(dailyAggDF, dailyTimeIntDF, by='date')
## calculate time spent in each category per day
print('Calculating daily duration by category ...')
for (i in 1:7) {
CATDurCol <- paste0('CAT', i, '_dur')
CATCntCol <- paste0('CAT', i, '_count')
dailyAggDF[[CATDurCol]] <- dailyAggDF[[CATCntCol]] * dailyAggDF$tInt
}
## calculate baseload duration (time spent in CAT1 and CAT2) per day
print('Calculating daily baseload duration (time spent in CAT1 and CAT2) ...')
dailyAggDF$baseload_dur <- dailyAggDF$CAT1_dur + dailyAggDF$CAT2_dur
## calculate baseload usage (energy spent in CAT1 and CAT2) per day
print ('Calculating daily baseload usage (energy spent in CAT1 and CAT2) ...')
dailyAggDF$usage_baseload <- dailyAggDF$CAT1_usage_sum + dailyAggDF$CAT2_usage_sum
## calculate mean baseload per day
print('Calculating daily mean baseload ...')
dailyAggDF$usage_baseload_mean <- (dailyAggDF$CAT1_usage_sum + dailyAggDF$CAT2_usage_sum) / (dailyAggDF$CAT1_count + dailyAggDF$CAT2_count)
## calculate peak ratio (also known as BL factor)
# 1.2
# BL Factor: The ratio of the highest reading divided by the BL
# (for the given time frame, typically daily)
print('Calculating daily peak ratio ...')
dailyAggDF$peakRatio <- dailyAggDF$usage_max / dailyAggDF$usage_baseload
dailyAggDF$peakRatio <- round(dailyAggDF$peakRatio, nRndDeci)
## calculate the percentage of time spent in baseload
dailyAggDF$baseload_dur_perc <- (dailyAggDF$baseload_dur) / 1440
## calculate the percentage of time spent in CAT7
dailyAggDF$CAT7_dur_perc <- dailyAggDF$CAT7_dur / 1440
## calculate the percentage of time spent in ramp-up-and-down
dailyAggDF$ramp_up_down_dur <- dailyAggDF$CAT3_dur + dailyAggDF$CAT4_dur + dailyAggDF$CAT5_dur
dailyAggDF$ramp_up_down_dur_perc <- dailyAggDF$ramp_up_down_dur / 1440
## calculate the ratio between average CAT6 and average CAT2 usage values
dailyAggDF$CAT6_CAT2_ratio <- dailyAggDF$CAT6_usage_mean / dailyAggDF$CAT2_usage_mean
#### SHOAIB'S CODE MODIFIED - START
#### SHOAIB'S CODE MODIFIED - START
#### SHOAIB'S CODE MODIFIED - START
#### SHOAIB'S CODE MODIFIED - START
dailyAggDF <- addYearMonth(dailyAggDF)  # adds year and month columns
dailyAggDF$week <- as.integer(format(dailyAggDF$date, '%W'))  # UK convention (week begins on Monday)
dailyAggDF$dateIndex <- as.integer(format(dailyAggDF$date, '%d'))
dailyAggDF$day <- weekdays(dailyAggDF$date, abbreviate = TRUE)
dailyAggDF$dayType <- as.factor(ifelse(dailyAggDF$day %in% c('Sat', 'Sun'), 'weekend', 'weekday'))
print(paste0("Calculating weekdata For a day"))
weeklyValuesForDay <- getWeekDataForDay(dailyAggDF, nPrWk = 4)
dailyAggDF <- merge(dailyAggDF, weeklyValuesForDay , by = "date" , all = 'TRUE')
print(paste0("Calculating daily days Over Consumption"))
daysOverConsumption <- days_over_consumption(dailyAggDF)
dailyAggDF <- merge(dailyAggDF, daysOverConsumption , by = "date" , all = 'TRUE')
print(paste0("Calculating daily Potential Saving"))
dailyPotentialSavings <- dailyPotentialSavings(dailyAggDF)
dailyAggDF <- merge(dailyAggDF, dailyPotentialSavings , by = "date" , all = 'TRUE')
print(paste0("Calculating daily abnormal Duration"))
abnlDurnDF <- calculateAbnormalDuration(dailyAggDF)
dailyAggDF <- merge(dailyAggDF, abnlDurnDF , by = "date" , all = 'TRUE')
print(paste0("Calculating daily Impact Value"))
dailyImpactDF <- calculateDailyImpact(dailyAggDF)
dailyAggDF <- merge(dailyAggDF , dailyImpactDF , by = "date" , all = 'TRUE')
dailyAggDF$sensitivity_factor <- 1.3
# if you want to off Alarm Code then
# comment below  three line
print(paste0("Calculating daily alarm"))
alarmDF <- baseloaddurationAlarm(dailyAggDF)
dailyAggDF <- merge(dailyAggDF, alarmDF, by ="date" , all = 'TRUE')
#### SHOAIB'S CODE MODIFIED - END
#### SHOAIB'S CODE MODIFIED - END
#### SHOAIB'S CODE MODIFIED - END
#### SHOAIB'S CODE MODIFIED - END
## return
return(dailyAggDF)
}
## this function takes logs dataset for multiple sensors
## and calculates various daily aggregation metrics
calcDailyAggMultSensors <- function(logsDF, nRndDeci=3) {
outputDF <- ddply(logsDF, "meterID", function(x) {
print(paste0('Meter ID: ', x$meterID[1]))
calcDailyAggSingleSensor(x)
})
return(outputDF)
}
## this function takes XYZ dataset for single sensor and
## calculates various monthly aggregation metrics
calcMonthlyAggSingleSensor <- function(logsDF, nRndDeci=3) {
## print meter ID
print(paste('Calculating monthly aggregation for', logsDF$meterID[1]))
## define aggregation methods
aggMeth <- c('count', 'sum', 'mean', 'sd', 'max', 'min')
## calculate basic monthly aggregation metrics per year-month
print(paste('Calculating monthly', paste(aggMeth, collapse=', '), '...'))
monthlyAggDF <- aggregate(df=logsDF, aggBy=c('year', 'month'), aggTarget='usage', aggMeth=aggMeth)
## calculate monthly category values per day
print(paste('Calculating monthly category values of', paste(aggMeth, collapse=', '), '...'))
monthlyCatValsDF <- calcCatValsSingleSensor(logsDF, 'monthly', aggMeth)
monthlyAggDF <- merge(monthlyAggDF, monthlyCatValsDF, by=c('year', 'month'))
## calculate time interval used per day
print('Calculating monthly time interval used for measurement ...')
monthlyTimeIntDF <- aggregate(logsDF, aggBy=c('year', 'month'), aggTarget='tInt', aggMeth='unique')
colnames(monthlyTimeIntDF)[colnames(monthlyTimeIntDF)=='tInt_unique'] <- 'tInt'
monthlyAggDF <- merge(monthlyAggDF, monthlyTimeIntDF, by=c('year', 'month'))
## calculate time spent in each category per day
print('Calculating monthly duration by category ...')
for (i in 1:7) {
CATDurCol <- paste0('CAT', i, '_dur')
CATCntCol <- paste0('CAT', i, '_count')
monthlyAggDF[[CATDurCol]] <- monthlyAggDF[[CATCntCol]] * monthlyAggDF$tInt
}
## calculate baseload duration (time spent in CAT1 and CAT2) per day
print('Calculating monthly baseload duration (time spent in CAT1 and CAT2) ...')
monthlyAggDF$baseload_dur <- monthlyAggDF$CAT1_dur + monthlyAggDF$CAT2_dur
## calculate baseload usage (energy spent in CAT1 and CAT2) per day
print ('Calculating monthly baseload usage (energy spent in CAT1 and CAT2) ...')
monthlyAggDF$usage_baseload <- monthlyAggDF$CAT1_usage_sum + monthlyAggDF$CAT2_usage_sum
## calculate mean baseload per day
print('Calculating monthly mean baseload ...')
monthlyAggDF$usage_baseload_mean <- (monthlyAggDF$CAT1_usage_sum + monthlyAggDF$CAT2_usage_sum) / (monthlyAggDF$CAT1_count + monthlyAggDF$CAT2_count)
## return
return(monthlyAggDF)
}
## this function takes XYZ dataset for single sensor and
## calculates various monthly aggregation metrics
calcMonthlyAggMultSensors <- function(logsDF, nRndDeci=3) {
outputDF <- ddply(logsDF, "meterID", function(x) {
print(paste0('Meter ID: ', x$meterID[1]))
calcMonthlyAggSingleSensor(x)
})
return(outputDF)
}
#### SHOAIB'S CODE - START ####
#### SHOAIB'S CODE - START ####
#### SHOAIB'S CODE - START ####
dailyPotentialSavings <- function(dayData) {
alldate <- dayData$date
daysValue <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daysValue) <- c("daily_potential_savings" , "date")
for(currentDate in 1: length(alldate)){
daysdata<- subset(dayData, as.POSIXct(date) == as.POSIXct(alldate[currentDate]))
#print(paste0("daysData is", daysdata))
potentialSavingValue <- (daysdata$usage_baseload_mean - daysdata$real_target)*(daysdata$CAT1_count+daysdata$CAT2_count)
if(is.na(potentialSavingValue) | potentialSavingValue < 0){
potentialSavingValue <- 0
}
dayValueDF <- data.frame(potentialSavingValue, alldate[currentDate])
colnames(dayValueDF)  <-   c("daily_potential_savings" , "date")
daysValue<-rbind(daysValue,dayValueDF)
}
return(daysValue)
}
## Comment by Howard:
## What is the definition of daily impact?
calculateDailyImpact <- function(df){
dailyImpactDF <- df[, c('days_over_consumption', 'usage_sum' ,'date') ]
dailyImpactDF <- ddply(dailyImpactDF, .(date), transform, daily_impact = (days_over_consumption/usage_sum)*100 )
dailyImpactDF <- subset(dailyImpactDF,select = c(date, daily_impact))
return(dailyImpactDF)
}
## Comment by Howard:
## what does this function do?
baseloaddurationAlarm <- function(df){
#print(paste0("starting of baseload duration alarm"))
dataForAlarm <- subset(df,select = c(date, baseload_dur, wk_bl_durn_mean,wk_bl_durn_sd, sensitivity_factor , daily_impact))
# to remove NA
dataForAlarm <-  dataForAlarm[complete.cases(dataForAlarm[,c("baseload_dur", "wk_bl_durn_mean", "wk_bl_durn_sd","daily_impact")]),]
alarmsData <- ddply(dataForAlarm, .(date), transform, alarm_code=baseload_duration_alarm_raised_cl3(wk_bl_durn_mean, wk_bl_durn_sd , baseload_dur, sensitivity_factor,daily_impact) )
alarm <- subset(alarmsData,select = c(date, alarm_code))
return(alarm)
}
## Comment by Howard:
## what does this function do?
baseload_duration_alarm_raised_cl3 <- function(wdbldmean,wdbldsd,dbld,sensitivity_factor , daily_impact){
daily_blduration <- dbld
weekday_duration_mean <- wdbldmean
weekday_duration_sd <- wdbldsd
if(daily_blduration < weekday_duration_mean - (weekday_duration_sd * sensitivity_factor)){
if(!is.na(daily_impact) && daily_impact > 3){
return("AL001")
}
else{
return("NA")
}
} else {
return("NA")
}
}
## Comment by Howard:
## what does this function do?
calculateAbnormalDuration <- function(df){
abnlData <- subset(df,select = c(date, baseload_dur, wk_bl_durn_mean))
dataWithAbnormalDuration <- ddply(abnlData, .(date), transform, abnl_durn=abnlDurn(baseload_dur,  wk_bl_durn_mean) )
df <- subset(dataWithAbnormalDuration,select = c(date, abnl_durn))
return(df)
}
## Comment by Howard:
## what does this function do?
## what is bld and wbldm?
abnlDurn <- function(bld, wbldm){
return(wbldm - bld)
}
## Comment by Howard:
## what does this function do?
## how do you define days over consumption?
days_over_consumption <- function(dayData)
{
alldate <- dayData$date
daysValue <- data.frame(matrix(ncol = 2, nrow = 0))
colnames(daysValue) <- c("days_over_consumption" , "date")
for(currentDate in 1: length(alldate)){
daysdata<- subset(dayData, as.POSIXct(date) == as.POSIXct(alldate[currentDate]))
#print(paste0("daysData is", daysdata))
val <- abs(get_avg_noblincrease(daysdata))
dayValueDF <- data.frame(val, alldate[currentDate])
colnames(dayValueDF)  <-   c("days_over_consumption" , "date")
daysValue<-rbind(daysValue,dayValueDF)
}
return(daysValue)
}
## Comment by Howard:
## what does this function do?
## what is noblincrease?
get_avg_noblincrease <- function(dayData)
{
other_increase_points <- 0
val3points <- 0
val4points  <- 0
val5points  <- 0
val6points  <- 0
val7points <- 0
val3points <- (dayData$CAT3_count - dayData$wk_cat3_num_avg)
val4points <- (dayData$CAT4_count - dayData$wk_cat4_num_avg)
val5points <- (dayData$CAT5_count - dayData$wk_cat5_num_avg)
val6points <- (dayData$CAT6_count - dayData$wk_cat6_num_avg)
val7points <- (dayData$CAT7_count - dayData$wk_cat7_num_avg)
if(  is.na(val3points) | val3points < 0){
val3points <- 0
}
if( is.na(val4points) | val4points < 0){
val4points <- 0
}
if( is.na(val5points) | val5points < 0){
val5points<-0
}
if(is.na(val6points) | val6points < 0){
val6points<-0
}
if(is.na(val7points) | val7points < 0){
val7points<-0
}
bl_kwh <- sum(dayData$CAT1_usage_mean*dayData$CAT1_count,dayData$CAT2_usage_mean*dayData$CAT2_count)
non_blincrease <- 0
non_blincrease <- (dayData$CAT3_usage_mean - bl_kwh)*val3points+(dayData$CAT4_usage_mean - bl_kwh)*val4points + (dayData$CAT5_usage_mean - bl_kwh)*val5points +(dayData$CAT6_usage_mean - bl_kwh)*val6points +(dayData$CAT7_usage_mean - bl_kwh)*val7points
other_increase_points <- val3points+val4points+val5points+val6points+val7points
avg_non_blusage <-0
if(val3points+val4points+val5points+val6points+val7points >0)
{
avg_non_blusage <- non_blincrease/(val3points+val4points+val5points+val6points+val7points)
}
return(avg_non_blusage)
}
## Comment by Howard:
## what does this function do?
getWeekDataForDay <- function (df, nPrWk){
dates <- df$date
weekdata <- data.frame(matrix(ncol = 11, nrow = 0))
colnames(weekdata) <- c("wk_cat1_num_avg",  "wk_cat2_num_avg" , "wk_cat3_num_avg" , "wk_cat4_num_avg" , "wk_cat5_num_avg", "wk_cat6_num_avg", "wk_cat7_num_avg" , "wk_bl_durn_mean", "wk_bl_durn_sd" , "real_target" ,"date")
for (date_counter in 1:length(dates)) {
startDate <- as.Date(dates[date_counter])-7*nPrWk
startDate <- as.POSIXct(startDate)
endDate <- as.Date(dates[date_counter])
endDate <- as.POSIXct(endDate)
WeekDaysData <-   subset(df , as.POSIXct(df$date)  > startDate & as.POSIXct(df$date)  < endDate )
weekValueDF <- calculateWeeklyValuesForDaysData(WeekDaysData)
weekValueDF$date <- as.Date(endDate)
colnames(weekValueDF) <- c("wk_cat1_num_avg",  "wk_cat2_num_avg" , "wk_cat3_num_avg" , "wk_cat4_num_avg" , "wk_cat5_num_avg", "wk_cat6_num_avg", "wk_cat7_num_avg" , "wk_bl_durn_mean", "wk_bl_durn_sd", "real_target" ,"date")
weekdata<-rbind(weekdata,weekValueDF)
}
return(weekdata)
}
## Comment by Howard:
## what does this function do?
## what are "weekly values"?
calculateWeeklyValuesForDaysData  <- function(df){
wk_cat1_num_avg <-mean(df$CAT1_count)
wk_cat2_num_avg <-mean(df$CAT2_count)
wk_cat3_num_avg <-mean(df$CAT3_count)
wk_cat4_num_avg <-mean(df$CAT4_count)
wk_cat5_num_avg <-mean(df$CAT5_count)
wk_cat6_num_avg <-mean(df$CAT6_count)
wk_cat7_num_avg <-mean(df$CAT7_count)
wk_bl_durn_mean <- mean(df$baseload_dur , na.rm = TRUE)
wk_bl_durn_sd   <- sd(df$baseload_dur, na.rm = TRUE)
realTargetData <- df[, c('usage_baseload_mean' ,'date') ]
realTargetData <- subset(realTargetData, realTargetData$usage_baseload_mean != "NA")
if(length(realTargetData$usage_baseload_mean) > 0)
{
real_target <- min(realTargetData$usage_baseload_mean ,  na.rm = TRUE)
}
else{
real_target <- 0
}
weekValue <- data.frame(wk_cat1_num_avg,wk_cat2_num_avg,wk_cat3_num_avg,wk_cat4_num_avg,wk_cat5_num_avg,wk_cat6_num_avg,wk_cat7_num_avg, wk_bl_durn_mean , wk_bl_durn_sd, real_target)
colnames(weekValue)  <- c("wk_cat1_num_avg"  , "wk_cat2_num_avg" , "wk_cat3_num_avg" , "wk_cat4_num_avg" , "wk_cat5_num_avg", "wk_cat6_num_avg", "wk_cat7_num_avg", "wk_bl_durn_mean" , "wk_bl_durn_sd" , real_target)
return (weekValue)
}
## this function takes in aggregated dataset and marks
## days with small energy usage fluctuations, which
## indicates potential 24-hour-closed or 24-hour-open days
markSmallFlucDays <- function(df, threshold=2.7) {
df$usageFluc <- ifelse(df$peakRatio >= threshold, 'fluc', 'smFluc')
df$usageFluc <- as.factor(df$usageFluc)
return(df)
}
## this function takes in logs dataset and performs daily aggregation
aggregateDaily <- function(logs, daily, dataPrevAgg, export=TRUE) {
## if data previously aggregated, return aggregated dataset
if (dataPrevAgg) {
return(daily)
}
## perform daily aggregation
daily <- calcDailyAggMultSensors(logs)
daily <- markSmallFlucDays(daily)
## specify data types
daily$date <- as.Date(daily$date)
daily$day <- relevelDaysOfWeek(daily$day)
daily$meterID <- as.factor(daily$meterID)
daily$dayType <- as.factor(daily$dayType)
daily$week <- as.integer(daily$week)
daily$dateIndex <- as.integer(daily$dateIndex)
## export aggregated data if the option is selected
if (export) {
dailyAggDataFilePath <- getFilePath(rawDatasetFileName, 'agg', 'daily')
write.csv(daily, dailyAggDataFilePath, row.names = FALSE)
}
## return data
return(daily)
}
## this dataset takes in logs dataset and performs monthly aggregation
aggregateMonthly <- function(logs, monthly, dataPrevAgg, export=TRUE) {
## if data previously aggregated, return aggregated dataset
if (dataPrevAgg) {
return(monthly)
}
## perform monthly aggregation
monthly <- calcMonthlyAggMultSensors(logs)
## specify data types
monthly$meterID <- as.factor(monthly$meterID)
## export aggregated data if the option is selected
if (export) {
monthlyAggDataFilePath <- getFilePath(rawDatasetFileName, 'agg', 'monthly')
write.csv(monthly, monthlyAggDataFilePath, row.names = FALSE)
}
## return
return(monthly)
}
dataPrevAggWeekly <- F
daily <- aggregateDaily(logs, daily, dataPrevAgg)
libs <- c('plyr', 'ggplot2', 'scales', 'strucchange', 'flexclust', 'gridExtra', 'shiny', 'caTools',
'rpart', 'rpart.plot', 'RColorBrewer', 'stringr', 'reshape2', 'gridExtra', 'devtools',
'dplyr')
lapply(libs, function(x) {
do.call("require", list(x))
})
dataPrevAggWeekly <- F
daily <- aggregateDaily(logs, daily, dataPrevAgg)
head(logs)
load_all('./code/helpers')
dataPrevAggWeekly <- F
daily <- aggregateDaily(logs, daily, dataPrevAgg)
libs <- c('plyr', 'ggplot2', 'scales', 'strucchange', 'flexclust', 'gridExtra', 'shiny', 'caTools',
'rpart', 'rpart.plot', 'RColorBrewer', 'stringr', 'reshape2', 'gridExtra', 'devtools',
'dplyr', 'data.table')
lapply(libs, function(x) {
do.call("require", list(x))
})
daily <- aggregateDaily(logs, daily, dataPrevAgg)
weekly <- aggregateWeekly(daily,weekly, dataPrevAggWeekly)
monthly <- aggregateMonthly(logs, monthly, dataPrevAgg)
runApp('./code/')
dateRange <- as.Date(range(logs$date))
meterIDs <- as.character(unique(logs$meterID))
meterIDsList <- as.list(meterIDs)
names(meterIDsList) <- meterIDs
years <- as.integer(format(as.Date(dateRange), '%Y'))
years <- years[1]:years[2]
months <- sprintf("%02d", seq(1:12))
runApp('./code/')
head(daily)
runApp()
rm(list = ls())
setwd('/Users/hawooksong/Desktop/shiny_data_explorer')
library(shiny)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp(0)
runApp()
runApp()
runApp()
